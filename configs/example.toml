[train]
steps = 1000
grad_clip = 1.0
dtype = "bfloat16"
local_batch_size = 16
global_batch_size = 256

[lr_scheduler]
decay_type = "linear"
warmup_steps = 0

[checkpoint]
save_freq = -1

[data]
tokenizer_path = "tokenizer"